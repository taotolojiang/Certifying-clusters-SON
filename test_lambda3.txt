n = 50 d = 2 k = 2 theta = 0.7

------
lambdamin = 0.0008259659223618324 lambda_max = 0.017883467581112953
lambda = 0.0009354716751737394 duality gap = 0.0049451523531729435 
  num_clust = 2 numvm_total = 50 num_distinct_clust = 2 num_inconclusive = 0
 clusters = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50]
  itcount = 2280 maxit = 50000
  clustering condition is true
Rand index = 0.5294117647058824;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.6212121212121212;
lambda = 0.001403207512760609 duality gap = 0.002382888202646427 
  num_clust = 2 numvm_total = 50 num_distinct_clust = 2 num_inconclusive = 0
 clusters = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50]
  itcount = 2392 maxit = 50000
  clustering condition is true
Rand index = 0.5294117647058824;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.6212121212121212;
lambda = 0.0018709433503474788 duality gap = 0.0008228529681559849 
  num_clust = 2 numvm_total = 50 num_distinct_clust = 2 num_inconclusive = 0
 clusters = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50]
  itcount = 2568 maxit = 50000
  clustering condition is true
Rand index = 0.5294117647058824;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.6212121212121212;
lambda = 0.0023386791879343484 duality gap = 9.191536219077534e-5 
  num_clust = 2 numvm_total = 50 num_distinct_clust = 2 num_inconclusive = 0
 clusters = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50]
  itcount = 2968 maxit = 50000
  clustering condition is true
Rand index = 0.5294117647058824;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.6212121212121212;
lambda = 0.002806415025521218 duality gap = 3.1614333693141816e-5 
  num_clust = 3 numvm_total = 50 num_distinct_clust = 2 num_inconclusive = 0
 clusters = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 5, 48, 49]
  itcount = 3136 maxit = 50000
  clustering condition is true
Rand index = 0.5301960784313725;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.6363636363636364;
lambda = 0.0032741508631080876 duality gap = 0.0007912902433417912 
  num_clust = 4 numvm_total = 50 num_distinct_clust = 2 num_inconclusive = 0
 clusters = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 5, 47, 48]
  itcount = 2432 maxit = 50000
  clustering condition is true
Rand index = 0.5309803921568628;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.6363636363636364;
lambda = 0.0037418867006949576 duality gap = 0.00034903337575542537 
  num_clust = 4 numvm_total = 50 num_distinct_clust = 2 num_inconclusive = 0
 clusters = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 5, 47, 48]
  itcount = 2536 maxit = 50000
  clustering condition is true
Rand index = 0.5309803921568628;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.6363636363636364;
lambda = 0.004209622538281827 duality gap = 0.00011543168875505216 
  num_clust = 4 numvm_total = 50 num_distinct_clust = 2 num_inconclusive = 0
 clusters = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 5, 47, 48]
  itcount = 2688 maxit = 50000
  clustering condition is true
Rand index = 0.5309803921568628;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.6363636363636364;
lambda = 0.004677358375868697 duality gap = 2.04701078700964e-5 
  num_clust = 4 numvm_total = 50 num_distinct_clust = 2 num_inconclusive = 0
 clusters = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 5, 47, 48]
  itcount = 2952 maxit = 50000
  clustering condition is true
Rand index = 0.5309803921568628;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.6363636363636364;
lambda = 0.005145094213455567 duality gap = 1.6884132492123172e-7 
  num_clust = 4 numvm_total = 50 num_distinct_clust = 2 num_inconclusive = 0
 clusters = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 5, 47, 48]
  itcount = 3816 maxit = 50000
  clustering condition is true
Rand index = 0.5309803921568628;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.6363636363636364;
lambda = 0.005612830051042436 duality gap = 1.05111037100869e-5 
  num_clust = 4 numvm_total = 50 num_distinct_clust = 2 num_inconclusive = 0
 clusters = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 22, 24, 16, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 5, 46, 47]
  itcount = 2848 maxit = 50000
  clustering condition is true
Rand index = 0.5301960784313725;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.6363636363636364;
lambda = 0.006080565888629306 duality gap = 5.152998028279399e-7 
  num_clust = 4 numvm_total = 50 num_distinct_clust = 2 num_inconclusive = 0
 clusters = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 22, 24, 16, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 5, 46, 47]
  itcount = 3288 maxit = 50000
  clustering condition is true
Rand index = 0.5301960784313725;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.6363636363636364;
lambda = 0.006548301726216175 duality gap = 6.59383658785373e-12 
  num_clust = 4 numvm_total = 50 num_distinct_clust = 2 num_inconclusive = 0
 clusters = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 22, 24, 16, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 5, 46, 47]
  itcount = 5400 maxit = 50000
  clustering condition is true
Rand index = 0.5301960784313725;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.6363636363636364;
lambda = 0.007016037563803045 duality gap = 0.020238250876559505 
  num_clust = 44 numvm_total = 50 num_distinct_clust = 1 num_inconclusive = 0
 clusters = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 4, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 7, 1, 1, 1]
  itcount = 896 maxit = 50000
  clustering condition is true
Rand index = 0.5137254901960784;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.5454545454545454;
lambda = 0.007483773401389915 duality gap = 0.0025955222409947964 
  num_clust = 44 numvm_total = 50 num_distinct_clust = 1 num_inconclusive = 0
 clusters = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 4, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 7, 1, 1, 1]
  itcount = 1208 maxit = 50000
  clustering condition is true
Rand index = 0.5137254901960784;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.5454545454545454;
lambda = 0.007951509238976785 duality gap = 0.003169927381463822 
  num_clust = 45 numvm_total = 50 num_distinct_clust = 1 num_inconclusive = 0
 clusters = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 6, 1, 1, 1]
  itcount = 1056 maxit = 50000
  clustering condition is true
Rand index = 0.5121568627450981;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.5454545454545454;
lambda = 0.008419245076563654 duality gap = 0.00017901113710649952 
  num_clust = 46 numvm_total = 50 num_distinct_clust = 1 num_inconclusive = 0
 clusters = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1]
  itcount = 1504 maxit = 50000
  clustering condition is true
Rand index = 0.5129411764705882;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.5454545454545454;
lambda = 0.008886980914150524 duality gap = 0.005641594566668573 
  num_clust = 47 numvm_total = 50 num_distinct_clust = 1 num_inconclusive = 0
 clusters = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1]
  itcount = 632 maxit = 50000
  clustering condition is true
Rand index = 0.5113725490196078;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.5454545454545454;
lambda = 0.009354716751737394 duality gap = 0.000971361777715174 
  num_clust = 47 numvm_total = 50 num_distinct_clust = 1 num_inconclusive = 0
 clusters = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1]
  itcount = 704 maxit = 50000
  clustering condition is true
Rand index = 0.5113725490196078;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.5454545454545454;
lambda = 0.009822452589324264 duality gap = 0.00010237989795314206 
  num_clust = 48 numvm_total = 50 num_distinct_clust = 1 num_inconclusive = 0
 clusters = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1]
  itcount = 728 maxit = 50000
  clustering condition is true
Rand index = 0.5105882352941177;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.5454545454545454;
lambda = 0.010290188426911134 duality gap = 0.0002258235014096499 
  num_clust = 49 numvm_total = 50 num_distinct_clust = 1 num_inconclusive = 0
 clusters = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1]
  itcount = 280 maxit = 50000
  clustering condition is true
Rand index = 0.5105882352941177;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.5454545454545454;
lambda = 0.010757924264498002 duality gap = 1.021638809106662e-7 
  num_clust = 50 numvm_total = 50 num_distinct_clust = 1 num_inconclusive = 0
 clusters = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
  itcount = 1104 maxit = 50000
  clustering condition is true
Rand index = 0.5098039215686274;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.5454545454545454;
We have reached the max lambda!
The means are located 1 standard deviation away from each other. 

The lambda values with best Rand index are [0.0032741508631080876]
 The corresponding Rand indices are [0.5309803921568628]
 The lambda values with best Rand index of a smaller data set are [0.002806415025521218]
 The corresponding Rand indices of smaller data set are [0.6363636363636364]
The lambda values are 0.0009354716751737394:0.0004677358375868697:0.011225660102084872
 The Rand indices are [0.5294117647058824, 0.5294117647058824, 0.5294117647058824, 0.5294117647058824, 0.5301960784313725, 0.5309803921568628, 0.5309803921568628, 0.5309803921568628, 0.5309803921568628, 0.5309803921568628, 0.5301960784313725, 0.5301960784313725, 0.5301960784313725, 0.5137254901960784, 0.5137254901960784, 0.5121568627450981, 0.5129411764705882, 0.5113725490196078, 0.5113725490196078, 0.5105882352941177, 0.5105882352941177, 0.5098039215686274]
 The Rand idices for a smaller data set are [0.6212121212121212, 0.6212121212121212, 0.6212121212121212, 0.6212121212121212, 0.6363636363636364, 0.6363636363636364, 0.6363636363636364, 0.6363636363636364, 0.6363636363636364, 0.6363636363636364, 0.6363636363636364, 0.6363636363636364, 0.6363636363636364, 0.5454545454545454, 0.5454545454545454, 0.5454545454545454, 0.5454545454545454, 0.5454545454545454, 0.5454545454545454, 0.5454545454545454, 0.5454545454545454, 0.5454545454545454]
=======================================
------
lambdamin = 0.00045166369003320916 lambda_max = 0.035766935162225906
lambda = 0.0018109299426129558 duality gap = 0.0010236856180654286 
  num_clust = 2 numvm_total = 50 num_distinct_clust = 2 num_inconclusive = 0
 clusters = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50]
  itcount = 2656 maxit = 50000
  clustering condition is true
Rand index = 0.5294117647058824;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.6212121212121212;
lambda = 0.0027163949139194336 duality gap = 7.933259826131689e-5 
  num_clust = 3 numvm_total = 50 num_distinct_clust = 2 num_inconclusive = 0
 clusters = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 5, 48, 49]
  itcount = 3112 maxit = 50000
  clustering condition is true
Rand index = 0.5301960784313725;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.6363636363636364;
lambda = 0.0036218598852259115 duality gap = 0.0023119296394042976 
  num_clust = 4 numvm_total = 50 num_distinct_clust = 2 num_inconclusive = 0
 clusters = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 5, 47, 48]
  itcount = 2360 maxit = 50000
  clustering condition is true
Rand index = 0.5309803921568628;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.6363636363636364;
lambda = 0.004527324856532389 duality gap = 0.0005856264667727373 
  num_clust = 4 numvm_total = 50 num_distinct_clust = 2 num_inconclusive = 0
 clusters = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 5, 47, 48]
  itcount = 2552 maxit = 50000
  clustering condition is true
Rand index = 0.5309803921568628;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.6363636363636364;
lambda = 0.005432789827838867 duality gap = 7.649237136320153e-5 
  num_clust = 4 numvm_total = 50 num_distinct_clust = 2 num_inconclusive = 0
 clusters = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 5, 47, 48]
  itcount = 2856 maxit = 50000
  clustering condition is true
Rand index = 0.5309803921568628;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.6363636363636364;
lambda = 0.006338254799145345 duality gap = 1.2476459687604802e-6 
  num_clust = 4 numvm_total = 50 num_distinct_clust = 2 num_inconclusive = 0
 clusters = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 5, 47, 48]
  itcount = 3544 maxit = 50000
  clustering condition is true
Rand index = 0.5309803921568628;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.6363636363636364;
lambda = 0.007243719770451823 duality gap = 3.006061706400942e-5 
  num_clust = 6 numvm_total = 50 num_distinct_clust = 2 num_inconclusive = 0
 clusters = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 22, 24, 25, 26, 27, 28, 29, 30, 5, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 5, 43, 44, 5, 45, 46]
  itcount = 2688 maxit = 50000
  clustering condition is true
Rand index = 0.5349019607843137;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.6363636363636364;
lambda = 0.008149184741758301 duality gap = 1.3604244486487005e-7 
  num_clust = 6 numvm_total = 50 num_distinct_clust = 2 num_inconclusive = 0
 clusters = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 22, 24, 25, 26, 27, 28, 29, 30, 5, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 5, 43, 44, 5, 45, 46]
  itcount = 3424 maxit = 50000
  clustering condition is true
Rand index = 0.5349019607843137;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.6363636363636364;
lambda = 0.009054649713064779 duality gap = 0.0033016824336300488 
  num_clust = 45 numvm_total = 50 num_distinct_clust = 1 num_inconclusive = 0
 clusters = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 6, 1, 1, 1]
  itcount = 1152 maxit = 50000
  clustering condition is true
Rand index = 0.5121568627450981;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.5454545454545454;
lambda = 0.009960114684371257 duality gap = 0.00022704849106958136 
  num_clust = 47 numvm_total = 50 num_distinct_clust = 1 num_inconclusive = 0
 clusters = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1]
  itcount = 1488 maxit = 50000
  clustering condition is true
Rand index = 0.5113725490196078;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.5454545454545454;
lambda = 0.010865579655677735 duality gap = 0.003440731591581425 
  num_clust = 48 numvm_total = 50 num_distinct_clust = 1 num_inconclusive = 0
 clusters = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
  itcount = 552 maxit = 50000
  clustering condition is true
Rand index = 0.5105882352941177;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.5454545454545454;
lambda = 0.011771044626984212 duality gap = 1.3371845852816477e-9 
  num_clust = 50 numvm_total = 50 num_distinct_clust = 1 num_inconclusive = 0
 clusters = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
  itcount = 24 maxit = 50000
  clustering condition is true
Rand index = 0.5098039215686274;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.5454545454545454;
We have reached the max lambda!
The means are located 2 standard deviation away from each other. 

The lambda values with best Rand index are [0.007243719770451823]
 The corresponding Rand indices are [0.5349019607843137]
 The lambda values with best Rand index of a smaller data set are [0.0027163949139194336]
 The corresponding Rand indices of smaller data set are [0.6363636363636364]
The lambda values are 0.0018109299426129558:0.0009054649713064779:0.02173115931135547
 The Rand indices are [0.5294117647058824, 0.5301960784313725, 0.5309803921568628, 0.5309803921568628, 0.5309803921568628, 0.5309803921568628, 0.5349019607843137, 0.5349019607843137, 0.5121568627450981, 0.5113725490196078, 0.5105882352941177, 0.5098039215686274]
 The Rand idices for a smaller data set are [0.6212121212121212, 0.6363636363636364, 0.6363636363636364, 0.6363636363636364, 0.6363636363636364, 0.6363636363636364, 0.6363636363636364, 0.6363636363636364, 0.5454545454545454, 0.5454545454545454, 0.5454545454545454, 0.5454545454545454]
=======================================
------
lambdamin = 0.00034739689766660916 lambda_max = 0.05365040274333886
lambda = 0.0026998899820502736 duality gap = 0.00010200115752923011 
  num_clust = 3 numvm_total = 50 num_distinct_clust = 2 num_inconclusive = 0
 clusters = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 5, 48, 49]
  itcount = 3200 maxit = 50000
  clustering condition is true
Rand index = 0.5301960784313725;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.6363636363636364;
lambda = 0.004049834973075411 duality gap = 0.0015531450633261557 
  num_clust = 4 numvm_total = 50 num_distinct_clust = 2 num_inconclusive = 0
 clusters = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 5, 47, 48]
  itcount = 2576 maxit = 50000
  clustering condition is true
Rand index = 0.5309803921568628;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.6363636363636364;
lambda = 0.005399779964100547 duality gap = 0.00011268779849160637 
  num_clust = 4 numvm_total = 50 num_distinct_clust = 2 num_inconclusive = 0
 clusters = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 5, 47, 48]
  itcount = 3016 maxit = 50000
  clustering condition is true
Rand index = 0.5309803921568628;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.6363636363636364;
lambda = 0.006749724955125684 duality gap = 3.201193976565264e-9 
  num_clust = 4 numvm_total = 50 num_distinct_clust = 2 num_inconclusive = 0
 clusters = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 5, 47, 48]
  itcount = 5016 maxit = 50000
  clustering condition is true
Rand index = 0.5309803921568628;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.6363636363636364;
lambda = 0.008099669946150821 duality gap = 7.271431331901113e-5 
  num_clust = 6 numvm_total = 50 num_distinct_clust = 2 num_inconclusive = 0
 clusters = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 22, 24, 25, 26, 27, 28, 29, 30, 5, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 5, 43, 44, 5, 45, 46]
  itcount = 2832 maxit = 50000
  clustering condition is true
Rand index = 0.5349019607843137;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.6363636363636364;
lambda = 0.009449614937175957 duality gap = 9.741957001097035e-7 
  num_clust = 6 numvm_total = 50 num_distinct_clust = 2 num_inconclusive = 0
 clusters = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 22, 24, 25, 26, 27, 28, 29, 30, 5, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 5, 43, 44, 5, 45, 46]
  itcount = 3448 maxit = 50000
  clustering condition is true
Rand index = 0.5349019607843137;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.6363636363636364;
lambda = 0.010799559928201094 duality gap = 1.7848833522293717e-10 
  num_clust = 6 numvm_total = 50 num_distinct_clust = 2 num_inconclusive = 40
 clusters = [1, 2, 3, 4, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 5, 0, 0]
  itcount = 50000 maxit = 50000
  clustering condition is false
Rand index = 0.021969080553295363;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.05263157894736842;
lambda = 0.01214950491922623 duality gap = 0.017807186120535334 
  num_clust = 48 numvm_total = 50 num_distinct_clust = 1 num_inconclusive = 0
 clusters = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
  itcount = 448 maxit = 50000
  clustering condition is true
Rand index = 0.5105882352941177;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.5454545454545454;
lambda = 0.013499449910251368 duality gap = 3.9956876207725145e-7 
  num_clust = 50 numvm_total = 50 num_distinct_clust = 1 num_inconclusive = 0
 clusters = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
  itcount = 32 maxit = 50000
  clustering condition is true
Rand index = 0.5098039215686274;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.5454545454545454;
We have reached the max lambda!
The means are located 3 standard deviation away from each other. 

The lambda values with best Rand index are [0.008099669946150821]
 The corresponding Rand indices are [0.5349019607843137]
 The lambda values with best Rand index of a smaller data set are [0.0026998899820502736]
 The corresponding Rand indices of smaller data set are [0.6363636363636364]
The lambda values are 0.0026998899820502736:0.0013499449910251368:0.032398679784603285
 The Rand indices are [0.5301960784313725, 0.5309803921568628, 0.5309803921568628, 0.5309803921568628, 0.5349019607843137, 0.5349019607843137, 0.021969080553295363, 0.5105882352941177, 0.5098039215686274]
 The Rand idices for a smaller data set are [0.6363636363636364, 0.6363636363636364, 0.6363636363636364, 0.6363636363636364, 0.6363636363636364, 0.6363636363636364, 0.05263157894736842, 0.5454545454545454, 0.5454545454545454]
=======================================
------
lambdamin = 0.0003142187091997057 lambda_max = 0.07153387032445181
lambda = 0.003592404451682576 duality gap = 0.0030426555026679125 
  num_clust = 4 numvm_total = 50 num_distinct_clust = 2 num_inconclusive = 0
 clusters = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 5, 47, 48]
  itcount = 2592 maxit = 50000
  clustering condition is true
Rand index = 0.5309803921568628;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.6363636363636364;
lambda = 0.005388606677523864 duality gap = 0.000133721210204385 
  num_clust = 4 numvm_total = 50 num_distinct_clust = 2 num_inconclusive = 0
 clusters = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 5, 47, 48]
  itcount = 3144 maxit = 50000
  clustering condition is true
Rand index = 0.5309803921568628;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.6363636363636364;
lambda = 0.007184808903365152 duality gap = 0.0004372737093945034 
  num_clust = 6 numvm_total = 50 num_distinct_clust = 2 num_inconclusive = 0
 clusters = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 22, 24, 25, 26, 27, 28, 29, 30, 5, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 5, 43, 44, 5, 45, 46]
  itcount = 2808 maxit = 50000
  clustering condition is true
Rand index = 0.5349019607843137;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.6363636363636364;
lambda = 0.00898101112920644 duality gap = 1.4236289189284435e-5 
  num_clust = 6 numvm_total = 50 num_distinct_clust = 2 num_inconclusive = 0
 clusters = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 22, 24, 25, 26, 27, 28, 29, 30, 5, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 5, 43, 44, 5, 45, 46]
  itcount = 3376 maxit = 50000
  clustering condition is true
Rand index = 0.5349019607843137;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.6363636363636364;
lambda = 0.010777213355047728 duality gap = 1.1341316785525383e-12 
  num_clust = 6 numvm_total = 50 num_distinct_clust = 2 num_inconclusive = 7
 clusters = [1, 2, 3, 4, 5, 6, 0, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 11, 0, 21, 0, 0, 22, 0, 23, 24, 25, 26, 5, 27, 28, 29, 30, 6, 31, 32, 33, 34, 35, 36, 37, 5, 0, 38, 5, 39, 0]
  itcount = 50000 maxit = 50000
  clustering condition is false
Rand index = 0.36787564766839376;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.05263157894736842;
lambda = 0.012573415580889015 duality gap = 0.002632845475091017 
  num_clust = 43 numvm_total = 50 num_distinct_clust = 2 num_inconclusive = 0
 clusters = [1, 1, 2, 1, 1, 3, 3, 1, 3, 1, 1, 1, 1, 3, 1, 1, 4, 3, 1, 3, 1, 3, 3, 3, 3, 3, 3, 1, 5, 3, 6, 1, 3, 3, 3, 1, 3, 3, 1, 1, 3, 7, 8, 1, 1, 3, 9, 1, 3, 3]
  itcount = 1872 maxit = 50000
  clustering condition is true
Rand index = 0.8752941176470588;
The smaller dataset has 11 points;
Rand index for a smaller data set = 1.0;
lambda = 0.014369617806730304 duality gap = 6.36853656033054e-7 
  num_clust = 45 numvm_total = 50 num_distinct_clust = 2 num_inconclusive = 0
 clusters = [1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 3, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 1, 4, 2, 5, 1, 2, 2, 2, 1, 2, 2, 1, 1, 2, 1, 6, 1, 1, 2, 7, 1, 2, 2]
  itcount = 2280 maxit = 50000
  clustering condition is true
Rand index = 0.9090196078431373;
The smaller dataset has 11 points;
Rand index for a smaller data set = 1.0;
lambda = 0.016165820032571592 duality gap = 0.0794545523499437 
  num_clust = 50 numvm_total = 50 num_distinct_clust = 1 num_inconclusive = 0
 clusters = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
  itcount = 8 maxit = 50000
  clustering condition is true
Rand index = 0.5098039215686274;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.5454545454545454;
We have reached the max lambda!
The means are located 4 standard deviation away from each other. 

The lambda values with best Rand index are [0.014369617806730304]
 The corresponding Rand indices are [0.9090196078431373]
 The lambda values with best Rand index of a smaller data set are [0.012573415580889015]
 The corresponding Rand indices of smaller data set are [1.0]
The lambda values are 0.003592404451682576:0.001796202225841288:0.04310885342019091
 The Rand indices are [0.5309803921568628, 0.5309803921568628, 0.5349019607843137, 0.5349019607843137, 0.36787564766839376, 0.8752941176470588, 0.9090196078431373, 0.5098039215686274]
 The Rand idices for a smaller data set are [0.6363636363636364, 0.6363636363636364, 0.6363636363636364, 0.6363636363636364, 0.05263157894736842, 1.0, 1.0, 0.5454545454545454]
=======================================
------
lambdamin = 0.000313066568982794 lambda_max = 0.08941733790556476
lambda = 0.004486520223727378 duality gap = 0.0009230049120105832 
  num_clust = 4 numvm_total = 50 num_distinct_clust = 2 num_inconclusive = 0
 clusters = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 5, 47, 48]
  itcount = 2904 maxit = 50000
  clustering condition is true
Rand index = 0.5309803921568628;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.6363636363636364;
lambda = 0.0067297803355910665 duality gap = 7.770722731947899e-9 
  num_clust = 4 numvm_total = 50 num_distinct_clust = 2 num_inconclusive = 0
 clusters = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 5, 47, 48]
  itcount = 5184 maxit = 50000
  clustering condition is true
Rand index = 0.5309803921568628;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.6363636363636364;
lambda = 0.008973040447454755 duality gap = 1.7480731003161054e-5 
  num_clust = 6 numvm_total = 50 num_distinct_clust = 2 num_inconclusive = 0
 clusters = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 22, 24, 25, 26, 27, 28, 29, 30, 5, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 5, 43, 44, 5, 45, 46]
  itcount = 3528 maxit = 50000
  clustering condition is true
Rand index = 0.5349019607843137;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.6363636363636364;
lambda = 0.011216300559318444 duality gap = 7.94570951256901e-8 
  num_clust = 18 numvm_total = 50 num_distinct_clust = 2 num_inconclusive = 0
 clusters = [1, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 6, 10, 6, 6, 6, 6, 19, 6, 20, 21, 6, 22, 5, 13, 23, 24, 25, 6, 6, 26, 27, 28, 29, 30, 31, 5, 6, 32, 5, 6, 6]
  itcount = 4496 maxit = 50000
  clustering condition is true
Rand index = 0.6070588235294118;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.8636363636363636;
lambda = 0.013459560671182133 duality gap = 0.002678930582078465 
  num_clust = 43 numvm_total = 50 num_distinct_clust = 2 num_inconclusive = 0
 clusters = [1, 1, 2, 1, 1, 3, 3, 1, 3, 1, 1, 1, 1, 3, 1, 1, 4, 3, 1, 3, 1, 3, 3, 3, 3, 3, 3, 1, 5, 3, 6, 1, 3, 3, 3, 1, 3, 3, 1, 1, 3, 7, 8, 1, 1, 3, 9, 1, 3, 3]
  itcount = 2224 maxit = 50000
  clustering condition is true
Rand index = 0.8752941176470588;
The smaller dataset has 11 points;
Rand index for a smaller data set = 1.0;
lambda = 0.015702820783045822 duality gap = 1.1107408681709785e-6 
  num_clust = 46 numvm_total = 50 num_distinct_clust = 2 num_inconclusive = 0
 clusters = [1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 1, 3, 2, 4, 1, 2, 2, 2, 1, 2, 2, 1, 1, 2, 1, 5, 1, 1, 2, 6, 1, 2, 2]
  itcount = 3512 maxit = 50000
  clustering condition is true
Rand index = 0.9262745098039216;
The smaller dataset has 11 points;
Rand index for a smaller data set = 1.0;
lambda = 0.01794608089490951 duality gap = 1.9194462765881326e-5 
  num_clust = 50 numvm_total = 50 num_distinct_clust = 1 num_inconclusive = 0
 clusters = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
  itcount = 96 maxit = 50000
  clustering condition is true
Rand index = 0.5098039215686274;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.5454545454545454;
We have reached the max lambda!
The means are located 5 standard deviation away from each other. 

The lambda values with best Rand index are [0.015702820783045822]
 The corresponding Rand indices are [0.9262745098039216]
 The lambda values with best Rand index of a smaller data set are [0.013459560671182133]
 The corresponding Rand indices of smaller data set are [1.0]
The lambda values are 0.004486520223727378:0.002243260111863689:0.05383824268472853
 The Rand indices are [0.5309803921568628, 0.5309803921568628, 0.5349019607843137, 0.6070588235294118, 0.8752941176470588, 0.9262745098039216, 0.5098039215686274]
 The Rand idices for a smaller data set are [0.6363636363636364, 0.6363636363636364, 0.6363636363636364, 0.8636363636363636, 1.0, 1.0, 0.5454545454545454]
=======================================
------
lambdamin = 0.0003309172060553372 lambda_max = 0.10730080548667772
lambda = 0.005381586134636653 duality gap = 0.00014878184174449416 
  num_clust = 4 numvm_total = 50 num_distinct_clust = 2 num_inconclusive = 0
 clusters = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 5, 47, 48]
  itcount = 3336 maxit = 50000
  clustering condition is true
Rand index = 0.5309803921568628;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.6363636363636364;
lambda = 0.00807237920195498 duality gap = 0.0001432285416740342 
  num_clust = 6 numvm_total = 50 num_distinct_clust = 2 num_inconclusive = 0
 clusters = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 22, 24, 25, 26, 27, 28, 29, 30, 5, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 5, 43, 44, 5, 45, 46]
  itcount = 3264 maxit = 50000
  clustering condition is true
Rand index = 0.5349019607843137;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.6363636363636364;
lambda = 0.010763172269273306 duality gap = 2.2070023125880688e-12 
  num_clust = 11 numvm_total = 50 num_distinct_clust = 2 num_inconclusive = 0
 clusters = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 11, 7, 21, 7, 7, 22, 7, 23, 24, 25, 26, 5, 27, 28, 29, 30, 6, 31, 32, 33, 34, 35, 36, 37, 5, 7, 38, 5, 39, 7]
  itcount = 10096 maxit = 50000
  clustering condition is true
Rand index = 0.552156862745098;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.8636363636363636;
lambda = 0.013453965336591633 duality gap = 0.003882087969486747 
  num_clust = 43 numvm_total = 50 num_distinct_clust = 2 num_inconclusive = 0
 clusters = [1, 1, 2, 1, 1, 3, 3, 1, 3, 1, 1, 1, 1, 3, 1, 1, 4, 3, 1, 3, 1, 3, 3, 3, 3, 3, 3, 1, 5, 3, 6, 1, 3, 3, 3, 1, 3, 3, 1, 1, 3, 7, 8, 1, 1, 3, 9, 1, 3, 3]
  itcount = 2384 maxit = 50000
  clustering condition is true
Rand index = 0.8752941176470588;
The smaller dataset has 11 points;
Rand index for a smaller data set = 1.0;
lambda = 0.01614475840390996 duality gap = 2.1748805920651648e-5 
  num_clust = 47 numvm_total = 50 num_distinct_clust = 2 num_inconclusive = 0
 clusters = [1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 3, 1, 2, 2, 2, 1, 2, 2, 1, 1, 2, 1, 4, 1, 1, 2, 5, 1, 2, 2]
  itcount = 3264 maxit = 50000
  clustering condition is true
Rand index = 0.9443137254901961;
The smaller dataset has 11 points;
Rand index for a smaller data set = 1.0;
lambda = 0.018835551471228285 duality gap = 0.0009267830100725405 
  num_clust = 49 numvm_total = 50 num_distinct_clust = 2 num_inconclusive = 0
 clusters = [1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 2, 3, 1, 2, 2]
  itcount = 2216 maxit = 50000
  clustering condition is true
Rand index = 0.9811764705882353;
The smaller dataset has 11 points;
Rand index for a smaller data set = 1.0;
lambda = 0.021526344538546613 duality gap = 0.11096669801554526 
  num_clust = 50 numvm_total = 50 num_distinct_clust = 1 num_inconclusive = 0
 clusters = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
  itcount = 40 maxit = 50000
  clustering condition is true
Rand index = 0.5098039215686274;
The smaller dataset has 11 points;
Rand index for a smaller data set = 0.5454545454545454;
We have reached the max lambda!
The means are located 6 standard deviation away from each other. 

The lambda values with best Rand index are [0.018835551471228285]
 The corresponding Rand indices are [0.9811764705882353]
 The lambda values with best Rand index of a smaller data set are [0.013453965336591633]
 The corresponding Rand indices of smaller data set are [1.0]
The lambda values are 0.005381586134636653:0.0026907930673183266:0.06457903361563984
 The Rand indices are [0.5309803921568628, 0.5349019607843137, 0.552156862745098, 0.8752941176470588, 0.9443137254901961, 0.9811764705882353, 0.5098039215686274]
 The Rand idices for a smaller data set are [0.6363636363636364, 0.6363636363636364, 0.8636363636363636, 1.0, 1.0, 1.0, 0.5454545454545454]
=======================================
